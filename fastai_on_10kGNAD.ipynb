{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_on_10kGNAD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTYi4i3XLcEFFTTuoDMrwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/NLP-with-fastai2.0/blob/main/fastai_on_10kGNAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kHwjgd0Xx1n"
      },
      "source": [
        "# !pip install fastai --upgrade\n",
        "# #==2.1.4\n",
        "# !pip install bpemb\n",
        "# !pip install cleantext "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivYJv0All5p3"
      },
      "source": [
        "# !wget https://github.com/tblock/10kGNAD/raw/master/train.csv\n",
        "# !wget https://github.com/tblock/10kGNAD/raw/master/test.csv\n",
        "# !ls"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK0IujBX3o5X"
      },
      "source": [
        "# !wget -O models/ulmfit_for_german_jfilter.pth https://github.com/jfilter/ulmfit-for-german/releases/download/0.1.0/ulmfit_for_german_jfilter.pth\n",
        "# !ls models/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx9BJbfRnSEN"
      },
      "source": [
        "# !mkdir nltk_data\n",
        "# !ls"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCTYKvQqpLm0"
      },
      "source": [
        "import nltk\n",
        "# nltk.download('stopwords', download_dir='nltk_data')\n",
        "nltk.data.path.append('nltk_data')\n",
        "# from nltk.corpus import stopwords"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA-U7pnqX-IK"
      },
      "source": [
        "import csv\n",
        "\n",
        "from bpemb import BPEmb\n",
        "from cleantext import clean\n",
        "#from fastai.callbacks import *\n",
        "#from fastai.imports import torch\n",
        "from fastai.text.all import *\n",
        "import pandas as pd\n",
        "\n",
        "#torch.cuda.set_device(2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPz0nVyYs8u"
      },
      "source": [
        "bpemb_de = BPEmb(lang=\"de\", vs=25000, dim=300)\n",
        "\n",
        "# construct the vocabulary by added a padding token with the ID 25000 (because of the bpemb_de vocab size)\n",
        "voc = bpemb_de.words + ['xxpad']\n",
        "#itos = dict(enumerate(voc))\n",
        "#voc = Vocab(itos)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmwn_hvFZ0Of"
      },
      "source": [
        "def load_data(filename):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with open(filename) as csvfile:\n",
        "        # follow the 10kGNAD creator's setup\n",
        "        reader = csv.reader(csvfile, delimiter=';', quotechar='\\'')\n",
        "        for row in reader:\n",
        "            labels.append(row[0])\n",
        "            texts.append(row[1])\n",
        "    df = pd.DataFrame({'label': labels, 'text': texts})\n",
        "    #df['text'] = df['text'].apply(lambda x: bpemb_de.encode_ids_with_bos_eos(clean(x, stp_lang='german')))\n",
        "                                                                                   #lang='de')))\n",
        "    df['text'] = df['text'].apply(lambda x: clean(x, extra_spaces=True, stopwords=False,\n",
        "                                                  lowercase=True, stp_lang='german'))\n",
        "    return df\n",
        "\n",
        "df_train_valid = load_data(\"train.csv\")\n",
        "\n",
        "# the last 1000 training samples are used for validation\n",
        "# df_train = df_train_valid.iloc[:-1000]\n",
        "# df_valid = df_train_valid.iloc[-1000:]\n",
        "\n",
        "df_test = load_data(\"test.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOGQ94K5l31t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "4932dbd1-767a-41f8-a123-629ceaa7d358"
      },
      "source": [
        "df_train_valid.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-jähriger fällt wohl bis saisonende aus. wien – rapid muss wohl bis saisonende auf offensivspieler thomas murg verzichten. der im winter aus ried gekommene 21-jährige erlitt beim 0:4-heimdebakel gegen admira wacker mödling am samstag einen teilriss des innenbandes im linken knie, wie eine magnetresonanz-untersuchung am donnerstag ergab. murg erhielt eine schiene, muss aber nicht operiert werden. dennoch steht ihm eine mehrwöchige pause bevor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kultur</td>\n",
              "      <td>erfundene bilder zu filmen, die als verloren gelten: \"the forbidden room\" von guy maddin und evan johnson ist ein surrealer ritt durch die magischen labyrinthe des frühen kinos. wien – die filmgeschichte ist ein friedhof der verlorenen. unter den begrabenen finden sich zahllose filme, von denen nur noch mysteriös oder abenteuerlich klingende namen kursieren; und solche, über die verstreut herumliegendes sekundärmaterial aufschluss erlaubt. einer davon ist the forbidden room, ein two-reeler von 1913/14, den der arbeitswütige us-regisseur allan dwan u. a. mit dem horrordarsteller lon chaney ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Web</td>\n",
              "      <td>der frischgekürte ceo sundar pichai setzt auf ein umgänglicheres führungsteam. die atmosphäre im silicon valley ist rau. da werden massenhaft mitarbeiter der direkten konkurrenz abgeworben, löhne mit firmenübergreifenden mauscheleien niedrig gehalten und untergebene wegen leicht verfehlter ziele vor die tür gesetzt. auch in der höchsten firmenebene werden brutale umgangsformen gepflegt: die wutausbrüche von apple-mitgründer steve jobs sind legendär, sein früherer geschäftspartner steve wozniak hätte ihn zu lebzeiten gerne als arschloch beschimpft, traute sich aber nicht. auch google-mitgrü...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>putin: \"einigung, dass wir menge auf niveau von jänner halten\". moskau – die russischen ölproduzenten wollen nach den worten von präsident wladimir putin ihre förderung in diesem jahr einfrieren. im großen und ganzen wurde eine einigung erzielt, dass wir die ölproduktion auf dem niveau von jänner halten werden, sagte putin am mittwoch in moskau. russland leidet wie andere förderstaaten unter dem drastischen einbruch der ölpreise. putin will die preise durch eine begrenzte förderung im in- und ausland stabilisieren. dazu hatte russland jüngst mit saudi-arabien und anderen großen förderlände...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Inland</td>\n",
              "      <td>estland sieht den künftigen österreichischen präsidenten auch als estnischen staatsbürger. wien/tallinn/pskow – die eltern des künftigen bundespräsidenten waren 1941 aus dem von sowjets besetzten estland in das damalige deutsche reich geflohen, wo 1944 in wien sascha van der bellen zur welt kam. estnische verwandte jubelten am dienstag über dessen wahlsieg, freude herrscht auch unter politikern des landes. interesse an van der bellen gibt es auch in der russischen stadt pskow, der geburtsstadt seiner eltern. wir haben von ganzem herzen und mit der ganzen familie mitgefiebert, sagt irina st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text\n",
              "0       Sport                                                                                                                                                         21-jähriger fällt wohl bis saisonende aus. wien – rapid muss wohl bis saisonende auf offensivspieler thomas murg verzichten. der im winter aus ried gekommene 21-jährige erlitt beim 0:4-heimdebakel gegen admira wacker mödling am samstag einen teilriss des innenbandes im linken knie, wie eine magnetresonanz-untersuchung am donnerstag ergab. murg erhielt eine schiene, muss aber nicht operiert werden. dennoch steht ihm eine mehrwöchige pause bevor.\n",
              "1      Kultur  erfundene bilder zu filmen, die als verloren gelten: \"the forbidden room\" von guy maddin und evan johnson ist ein surrealer ritt durch die magischen labyrinthe des frühen kinos. wien – die filmgeschichte ist ein friedhof der verlorenen. unter den begrabenen finden sich zahllose filme, von denen nur noch mysteriös oder abenteuerlich klingende namen kursieren; und solche, über die verstreut herumliegendes sekundärmaterial aufschluss erlaubt. einer davon ist the forbidden room, ein two-reeler von 1913/14, den der arbeitswütige us-regisseur allan dwan u. a. mit dem horrordarsteller lon chaney ...\n",
              "2         Web  der frischgekürte ceo sundar pichai setzt auf ein umgänglicheres führungsteam. die atmosphäre im silicon valley ist rau. da werden massenhaft mitarbeiter der direkten konkurrenz abgeworben, löhne mit firmenübergreifenden mauscheleien niedrig gehalten und untergebene wegen leicht verfehlter ziele vor die tür gesetzt. auch in der höchsten firmenebene werden brutale umgangsformen gepflegt: die wutausbrüche von apple-mitgründer steve jobs sind legendär, sein früherer geschäftspartner steve wozniak hätte ihn zu lebzeiten gerne als arschloch beschimpft, traute sich aber nicht. auch google-mitgrü...\n",
              "3  Wirtschaft  putin: \"einigung, dass wir menge auf niveau von jänner halten\". moskau – die russischen ölproduzenten wollen nach den worten von präsident wladimir putin ihre förderung in diesem jahr einfrieren. im großen und ganzen wurde eine einigung erzielt, dass wir die ölproduktion auf dem niveau von jänner halten werden, sagte putin am mittwoch in moskau. russland leidet wie andere förderstaaten unter dem drastischen einbruch der ölpreise. putin will die preise durch eine begrenzte förderung im in- und ausland stabilisieren. dazu hatte russland jüngst mit saudi-arabien und anderen großen förderlände...\n",
              "4      Inland  estland sieht den künftigen österreichischen präsidenten auch als estnischen staatsbürger. wien/tallinn/pskow – die eltern des künftigen bundespräsidenten waren 1941 aus dem von sowjets besetzten estland in das damalige deutsche reich geflohen, wo 1944 in wien sascha van der bellen zur welt kam. estnische verwandte jubelten am dienstag über dessen wahlsieg, freude herrscht auch unter politikern des landes. interesse an van der bellen gibt es auch in der russischen stadt pskow, der geburtsstadt seiner eltern. wir haben von ganzem herzen und mit der ganzen familie mitgefiebert, sagt irina st..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r_DPq0S147J",
        "outputId": "be108b74-6823-439f-e60a-f41add6d2d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " np.random.seed(1)\n",
        " msk = np.random.rand(df_train_valid.shape[0]) < 0.2\n",
        " df_train_valid['is_valid'] = msk\n",
        " print(df_train_valid.groupby(['is_valid','label'])['text'].count())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_valid  label        \n",
            "False     Etat              480\n",
            "          Inland            718\n",
            "          International    1089\n",
            "          Kultur            374\n",
            "          Panorama         1206\n",
            "          Sport             874\n",
            "          Web              1209\n",
            "          Wirtschaft       1012\n",
            "          Wissenschaft      412\n",
            "True      Etat              121\n",
            "          Inland            195\n",
            "          International     271\n",
            "          Kultur            111\n",
            "          Panorama          304\n",
            "          Sport             207\n",
            "          Web               300\n",
            "          Wirtschaft        258\n",
            "          Wissenschaft      104\n",
            "Name: text, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBj7Asytham",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "9e119c1b-1c30-4547-b949-aee8efce0f03"
      },
      "source": [
        "#data_lm = TextLMDataBunch.from_ids('uf_de_exp', bs=128, vocab=voc, train_ids=df_train['text'], valid_ids=df_valid['text'])\n",
        "data_lm = DataBlock(\n",
        "            blocks=TextBlock.from_df('text', is_lm=True, vocab = voc),\n",
        "            get_x=ColReader('text'),\n",
        "            splitter=RandomSplitter(0.1))\n",
        "\n",
        "dls_lm = data_lm.dataloaders(df_train_valid) \n",
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;unk&gt; &lt;unk&gt; konzert i m wiener theater am &lt;unk&gt; . wien – es kam , wie es kommen &lt;unk&gt; . &lt;unk&gt; war die &lt;unk&gt; &lt;unk&gt; . &lt;unk&gt; das zu singen &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; am &lt;unk&gt; keine lust mehr , also ließ er das &lt;unk&gt; zum abschluss sich selbst &lt;unk&gt; . &lt;unk&gt; aber war das &lt;unk&gt; konzert einer der &lt;unk&gt; des &lt;unk&gt; wien i m &lt;unk&gt; - &lt;unk&gt; i m wiener theater am</td>\n",
              "      <td>&lt;unk&gt; konzert i m wiener theater am &lt;unk&gt; . wien – es kam , wie es kommen &lt;unk&gt; . &lt;unk&gt; war die &lt;unk&gt; &lt;unk&gt; . &lt;unk&gt; das zu singen &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; am &lt;unk&gt; keine lust mehr , also ließ er das &lt;unk&gt; zum abschluss sich selbst &lt;unk&gt; . &lt;unk&gt; aber war das &lt;unk&gt; konzert einer der &lt;unk&gt; des &lt;unk&gt; wien i m &lt;unk&gt; - &lt;unk&gt; i m wiener theater am &lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>- mit &lt;unk&gt; aus den &lt;unk&gt; jahren &lt;unk&gt; . i m jahr 2 &lt;unk&gt; &lt;unk&gt; 0 &lt;unk&gt; &lt;unk&gt; die &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; , &lt;unk&gt; &lt;unk&gt; systems für den &lt;unk&gt; &lt;unk&gt; - und die planung gleich wieder auf eis gelegt , weil damals die &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; . erst i m juni &lt;unk&gt; &lt;unk&gt; auf basis des ( wenn auch &lt;unk&gt; ) alten &lt;unk&gt; mit einer &lt;unk&gt; &lt;unk&gt; - &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
              "      <td>mit &lt;unk&gt; aus den &lt;unk&gt; jahren &lt;unk&gt; . i m jahr 2 &lt;unk&gt; &lt;unk&gt; 0 &lt;unk&gt; &lt;unk&gt; die &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; , &lt;unk&gt; &lt;unk&gt; systems für den &lt;unk&gt; &lt;unk&gt; - und die planung gleich wieder auf eis gelegt , weil damals die &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; . erst i m juni &lt;unk&gt; &lt;unk&gt; auf basis des ( wenn auch &lt;unk&gt; ) alten &lt;unk&gt; mit einer &lt;unk&gt; &lt;unk&gt; - &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; ,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "ZsTlUkVcYfHW",
        "outputId": "630eec80-6cf2-49fe-a9c8-e3ed2820b12f"
      },
      "source": [
        "# learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "# learn_lm.load('/mnt/data/group07/johannes/germanlm/exp_10/models/2019_ 4_14_20_48_17_552279')\n",
        "\n",
        "config = awd_lstm_lm_config.copy()\n",
        "config['n_hid'] = 1150\n",
        "learn_lm = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.5, \n",
        "                                  pretrained=False, config=config,\n",
        "                                metrics=[accuracy, Perplexity()]).to_fp16()\n",
        "\n",
        "learn_lm.load('ulmfit_for_german_jfilter')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-731340e01850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 metrics=[accuracy, Perplexity()]).to_fp16()\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ulmfit_for_german_jfilter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, with_opt, device, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mload_model_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload_model_text\u001b[0;34m(file, model, opt, with_opt, device, strict)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mhasopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_raw_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tsize mismatch for 0.rnns.0.weight_hh_l0_raw: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).\n\tsize mismatch for 0.rnns.0.module.weight_ih_l0: copying a param with shape torch.Size([4600, 400]) from checkpoint, the shape in current model is torch.Size([4608, 400]).\n\tsize mismatch for 0.rnns.0.module.bias_ih_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for 0.rnns.0.module.bias_hh_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for 0.rnns.1.weight_hh_l0_raw: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).\n\tsize mismatch for 0.rnns.1.module.weight_ih_l0: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).\n\tsize mismatch for 0.rnns.1.module.bias_ih_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for 0.rnns.1.module.bias_hh_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).\n\tsize mismatch for 0.rnns.2.module.weight_ih_l0: copying a param with shape torch.Size([1600, 1150]) from checkpoint, the shape in current model is torch.Size([1600, 1152])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "1zuG_b54bBX0",
        "outputId": "78a42a27-d3df-4dd8-97dc-a831df158f3a"
      },
      "source": [
        "learn_lm.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.934346</td>\n",
              "      <td>2.860454</td>\n",
              "      <td>0.438395</td>\n",
              "      <td>17.469450</td>\n",
              "      <td>12:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "UFE0jkp8bEHU",
        "outputId": "19473d0f-92fb-47fb-ed2b-ff3ddf6b7166"
      },
      "source": [
        "learn_lm.unfreeze()\n",
        "learn_lm.fit_one_cycle(10, 1e-3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.887461</td>\n",
              "      <td>2.847165</td>\n",
              "      <td>0.439507</td>\n",
              "      <td>17.238834</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.869438</td>\n",
              "      <td>2.828527</td>\n",
              "      <td>0.440575</td>\n",
              "      <td>16.920519</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.849066</td>\n",
              "      <td>2.806899</td>\n",
              "      <td>0.442118</td>\n",
              "      <td>16.558483</td>\n",
              "      <td>12:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.824777</td>\n",
              "      <td>2.791699</td>\n",
              "      <td>0.443337</td>\n",
              "      <td>16.308708</td>\n",
              "      <td>12:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.798625</td>\n",
              "      <td>2.779075</td>\n",
              "      <td>0.444201</td>\n",
              "      <td>16.104124</td>\n",
              "      <td>12:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.777349</td>\n",
              "      <td>2.769854</td>\n",
              "      <td>0.445020</td>\n",
              "      <td>15.956302</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.766179</td>\n",
              "      <td>2.764022</td>\n",
              "      <td>0.445790</td>\n",
              "      <td>15.863512</td>\n",
              "      <td>12:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.750811</td>\n",
              "      <td>2.760812</td>\n",
              "      <td>0.445924</td>\n",
              "      <td>15.812671</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.751819</td>\n",
              "      <td>2.759194</td>\n",
              "      <td>0.446095</td>\n",
              "      <td>15.787115</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.735645</td>\n",
              "      <td>2.759099</td>\n",
              "      <td>0.446073</td>\n",
              "      <td>15.785606</td>\n",
              "      <td>12:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2D0zXFIb5Pb"
      },
      "source": [
        "learn_lm.save_encoder('german_lm_finetuned')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gexyDkpdFmrN",
        "outputId": "55da4689-101e-46ac-c141-71d93b38f891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "# Note the use of the langauge model vocab in the data block\n",
        "data_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_df('text',vocab=dls_lm.vocab), CategoryBlock),\n",
        "    get_x=ColReader('text'), get_y=ColReader('label'), splitter=ColSplitter())\n",
        "\n",
        "dls_clas = data_clas.dataloaders(df_train_valid,valid_col='is_valid',\n",
        "                                      seed=1, shuffle_train=True) \n",
        "\n",
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;unk&gt; neues &lt;unk&gt; &lt;unk&gt; seit &lt;unk&gt; als &lt;unk&gt; an &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; . da ist es &lt;unk&gt; also . das erste &lt;unk&gt; unter der &lt;unk&gt; des neuen &lt;unk&gt; - &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; . und sein &lt;unk&gt; namens &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; nicht nur &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; , die mit dem zu &lt;unk&gt; auf &lt;unk&gt; first &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; , &lt;unk&gt; auch die &lt;unk&gt; von &lt;unk&gt; &lt;unk&gt; als &lt;unk&gt; &lt;unk&gt; . seit heute &lt;unk&gt; &lt;unk&gt; sein neues &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; an &lt;unk&gt; &lt;unk&gt; – als &lt;unk&gt; . das &lt;unk&gt; gibt es &lt;unk&gt; für alle , die &lt;unk&gt; mit &lt;unk&gt; &lt;unk&gt; oder &lt;unk&gt; arbeiten . später &lt;unk&gt; es &lt;unk&gt; &lt;unk&gt; auf allen geräten laufen , auch auf dem &lt;unk&gt; und der &lt;unk&gt; . einen &lt;unk&gt; &lt;unk&gt; es nicht mehr geben – nur noch &lt;unk&gt; &lt;unk&gt; und &lt;unk&gt; . nach &lt;unk&gt; &lt;unk&gt; mit dem &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; die &lt;unk&gt;</td>\n",
              "      <td>Web</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;unk&gt; &lt;unk&gt; auf dem &lt;unk&gt; und &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; kein &lt;unk&gt; , sagen &lt;unk&gt; &lt;unk&gt; und &lt;unk&gt; &lt;unk&gt; über den &lt;unk&gt; von &lt;unk&gt; . wien – &lt;unk&gt; ist seit &lt;unk&gt; in österreich . &lt;unk&gt; alm mit &lt;unk&gt; agentur super - fi und &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; das magazin nach österreich . &lt;unk&gt; zehn jahre später &lt;unk&gt; das &lt;unk&gt; als &lt;unk&gt; &lt;unk&gt; und anker für &lt;unk&gt; mit nach eigenen angaben &lt;unk&gt; &lt;unk&gt; , &lt;unk&gt; zwei &lt;unk&gt; in der agentur &lt;unk&gt; und ein &lt;unk&gt; für das &lt;unk&gt; &lt;unk&gt; arbeiten . alm hat die &lt;unk&gt; &lt;unk&gt; und das &lt;unk&gt; stellt sich neu auf : mit der redaktion auf der einen seite und der agentur &lt;unk&gt; auf der &lt;unk&gt; . &lt;unk&gt; geht aus dem &lt;unk&gt; der &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; digital &lt;unk&gt; , &lt;unk&gt; , &lt;unk&gt; , &lt;unk&gt; und &lt;unk&gt; &lt;unk&gt; und aus der &lt;unk&gt; der &lt;unk&gt; super - fi . &lt;unk&gt; pläne mit der neuen</td>\n",
              "      <td>Etat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;unk&gt; &lt;unk&gt; mit mut zu &lt;unk&gt; design und &lt;unk&gt; &lt;unk&gt; aus der masse heraus . es &lt;unk&gt; nur selten , &lt;unk&gt; ein neues &lt;unk&gt; in der redaktion &lt;unk&gt; , das &lt;unk&gt; aus der masse &lt;unk&gt; . &lt;unk&gt; es &lt;unk&gt; fast so , als &lt;unk&gt; sich die großen hersteller &lt;unk&gt; &lt;unk&gt; auf eine &lt;unk&gt; design - linie &lt;unk&gt; . um so &lt;unk&gt; ist es , wenn &lt;unk&gt; &lt;unk&gt; ein &lt;unk&gt; &lt;unk&gt; , das aus &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; – vor &lt;unk&gt; , wenn es von &lt;unk&gt; &lt;unk&gt; kommt , der noch &lt;unk&gt; mit &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; . &lt;unk&gt; &lt;unk&gt; das erste &lt;unk&gt; von &lt;unk&gt; , das all dies &lt;unk&gt; . das unternehmen selbst ist &lt;unk&gt; ein &lt;unk&gt; in der branche , die &lt;unk&gt; personen &lt;unk&gt; es nicht . die &lt;unk&gt; gründer haben &lt;unk&gt; &lt;unk&gt; jahre lang für &lt;unk&gt; an &lt;unk&gt; &lt;unk&gt; . für die gestaltung der &lt;unk&gt; &lt;unk&gt; mit &lt;unk&gt; &lt;unk&gt;</td>\n",
              "      <td>Web</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12-RLEqeGdDn"
      },
      "source": [
        "fscore = F1Score(average='weighted')\n",
        "#ls_func = CrossEntropyLossFlat()\n",
        "#random_seed(32, True)\n",
        "cls_config = awd_lstm_clas_config.copy()\n",
        "cls_config['n_hid'] = 1150\n",
        "learn_cls = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
        "                                #loss_func = ls_func,\n",
        "                                pretrained=False, config=cls_config,\n",
        "                                metrics=[accuracy,fscore])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_f6BDUnGjiV"
      },
      "source": [
        "learn_cls = learn_cls.load_encoder('german_lm_finetuned')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvdmAUnhKnKq",
        "outputId": "98288a89-79b8-42b3-cfa3-3f3d0da96824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "learn_cls.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='77' class='' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      66.96% [77/115 01:05<00:32 0.7851]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVy8wOuGupv",
        "outputId": "92bb6e4b-7ecb-4ad2-bf39-534573584700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn_cls.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.872505</td>\n",
              "      <td>0.647173</td>\n",
              "      <td>0.772314</td>\n",
              "      <td>0.771449</td>\n",
              "      <td>02:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSPrU9-yGzk8"
      },
      "source": [
        "learn_cls.freeze_to(-2)\n",
        "learn_cls.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq0DF1_nG1og"
      },
      "source": [
        "learn_cls.freeze_to(-3)\n",
        "learn_cls.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ET9Yj8UG3pg"
      },
      "source": [
        "learn_cls.unfreeze()\n",
        "learn_cls.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBgHXZooKJC_"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbrFevBsKJvT"
      },
      "source": [
        "act_class = [str(c) for c in df_test.title.values]\n",
        "len(np.unique(act_class))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxSl4A7iG6DB"
      },
      "source": [
        "predict_df_lm = df_test.text.apply(learn_cls.predict)\n",
        "#predict_df.head()\n",
        "predict_df_class_lm = [x[0] for x in predict_df_lm.values]\n",
        "predict_df_prob_lm = [max(x[2].tolist()) for x in predict_df_lm.values]\n",
        "print(predict_df_class_lm[:10])\n",
        "print(predict_df_prob_lm[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh-5-nRWHABL"
      },
      "source": [
        "print(classification_report(act_class, predict_df_class_lm))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}